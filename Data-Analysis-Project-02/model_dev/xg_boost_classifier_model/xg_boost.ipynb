{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42cfdf99",
   "metadata": {},
   "source": [
    "## **Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e0ede76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report,f1_score,accuracy_score,precision_score,recall_score\n",
    "from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder,StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8c18e",
   "metadata": {},
   "source": [
    "## **Load the Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ce9e5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"C:\\\\UOC pdf\\\\4th Year\\\\Machine Learning-02\\\\Data-Analysis-Project-2\\\\data\\\\train_data.csv\")\n",
    "test_data=pd.read_csv(\"C:\\\\UOC pdf\\\\4th Year\\\\Machine Learning-02\\\\Data-Analysis-Project-2\\\\data\\\\test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dbdb282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data.drop(columns=[\"Unnamed: 0\"],axis=1)\n",
    "test_data=test_data.drop(columns=[\"Unnamed: 0\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ded6dc",
   "metadata": {},
   "source": [
    "## **Split X_train,Y_train,X_test,Y_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "84e15ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_data.drop(columns=[\"diagnosis\"],axis=1)\n",
    "Y_train=train_data[\"diagnosis\"]\n",
    "X_test=test_data.drop(columns=[\"diagnosis\"],axis=1)\n",
    "Y_test=test_data[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "73d330b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Training set:((700, 15), (700,))\n",
      "Shape of  the Testing set:((300, 15), (300,))\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of the Training set:{X_train.shape,Y_train.shape}\")\n",
    "print(f\"Shape of  the Testing set:{X_test.shape,Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd3c103",
   "metadata": {},
   "source": [
    "## **Build the Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f708d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=X_train.select_dtypes(include=\"number\").columns  ##get the all numerical column names\n",
    "cat_cols=X_train.select_dtypes(include=[\"object\",\"category\"]).columns ##get the all categorical column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "633ffc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_cols=[\"gender\",\"pem_present\",\"meditation_or_mindfulness\"] ##nominal columns\n",
    "ordinal_cols=[\"work_status\",\"social_activity_level\",\"exercise_frequency\"] ##ordinal columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e7ee9d",
   "metadata": {},
   "source": [
    "#### **Define the Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "66fd324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_pipeline=Pipeline(steps=[\n",
    "    (\"Ordinal Encoder\",OrdinalEncoder())      ##Ordinal variable pipeline\n",
    "])\n",
    "nominal_pipeline=Pipeline(steps=[\n",
    "    (\"Nominal Encoder\",OneHotEncoder(sparse_output=False,handle_unknown=\"ignore\"))  ##Nominal variable pipeline\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df9d33b",
   "metadata": {},
   "source": [
    "#### **Combine Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8b083ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transfomers=ColumnTransformer(transformers=[\n",
    "    (\"Ordinal Pipeline\",ordinal_pipeline,ordinal_cols), ##Combine the Ordinal Pipeline with Ordinal Columns\n",
    "    (\"Nominal Pipeline\",nominal_pipeline,nominal_cols)   ##Combine the Nominal Pipeline with Nominal Columns\n",
    "],\n",
    "   n_jobs=-1,\n",
    "   verbose=True,\n",
    "   remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66359920",
   "metadata": {},
   "source": [
    "#### **End Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4dbc2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline=Pipeline(steps=[\n",
    "    (\"Preprocessing\",Transfomers),  ##Preprocessing Step\n",
    "    (\"Resampling SMOTE\",SMOTE(random_state=42)),  ##SMOTE Resampling Method\n",
    "    (\"XGB Classifier\",XGBClassifier(reg_alpha=1,reg_lambda=1,min_child_weight=3)) ##Apply XGB Classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0612dcc8",
   "metadata": {},
   "source": [
    "#### **Make the Reponse variable as 0,1,2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c4bc4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=pd.DataFrame(Y_train)\n",
    "Y_test=pd.DataFrame(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b37b5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.Resposne variable\n",
    "# Replace 0.0 with 'Both', 1.0 with 'Depression' and 2.0 with ME/CFS\n",
    "Y_train[\"diagnosis\"] = Y_train[\"diagnosis\"].map({\"Both\":0,\"Depression\":1,\"ME/CFS\":2})\n",
    "Y_test[\"diagnosis\"] = Y_test[\"diagnosis\"].map({\"Both\":0,\"Depression\":1,\"ME/CFS\":2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0064d5",
   "metadata": {},
   "source": [
    "#### **Execute Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3e3dd87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Preprocessing&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;Ordinal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Ordinal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;work_status&#x27;,\n",
       "                                                   &#x27;social_activity_level&#x27;,\n",
       "                                                   &#x27;exercise_frequency&#x27;]),\n",
       "                                                 (&#x27;Nominal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Nominal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;pem_presen...\n",
       "                               feature_types=None, feature_weights=None,\n",
       "                               gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=3, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=None, n_jobs=None,\n",
       "                               num_parallel_tree=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;Preprocessing&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;Ordinal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Ordinal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;work_status&#x27;,\n",
       "                                                   &#x27;social_activity_level&#x27;,\n",
       "                                                   &#x27;exercise_frequency&#x27;]),\n",
       "                                                 (&#x27;Nominal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Nominal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;pem_presen...\n",
       "                               feature_types=None, feature_weights=None,\n",
       "                               gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=3, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=None, n_jobs=None,\n",
       "                               num_parallel_tree=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Preprocessing: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for Preprocessing: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(n_jobs=-1,\n",
       "                  transformers=[(&#x27;Ordinal Pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Ordinal Encoder&#x27;,\n",
       "                                                  OrdinalEncoder())]),\n",
       "                                 [&#x27;work_status&#x27;, &#x27;social_activity_level&#x27;,\n",
       "                                  &#x27;exercise_frequency&#x27;]),\n",
       "                                (&#x27;Nominal Pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Nominal Encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;gender&#x27;, &#x27;pem_present&#x27;,\n",
       "                                  &#x27;meditation_or_mindfulness&#x27;])],\n",
       "                  verbose=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Ordinal Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;work_status&#x27;, &#x27;social_activity_level&#x27;, &#x27;exercise_frequency&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OrdinalEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">?<span>Documentation for OrdinalEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OrdinalEncoder()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Nominal Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;gender&#x27;, &#x27;pem_present&#x27;, &#x27;meditation_or_mindfulness&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SMOTE</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(random_state=42)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=3, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Preprocessing',\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[('Ordinal Pipeline',\n",
       "                                                  Pipeline(steps=[('Ordinal '\n",
       "                                                                   'Encoder',\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  ['work_status',\n",
       "                                                   'social_activity_level',\n",
       "                                                   'exercise_frequency']),\n",
       "                                                 ('Nominal Pipeline',\n",
       "                                                  Pipeline(steps=[('Nominal '\n",
       "                                                                   'Encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['gender', 'pem_presen...\n",
       "                               feature_types=None, feature_weights=None,\n",
       "                               gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=3, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=None, n_jobs=None,\n",
       "                               num_parallel_tree=None, ...))])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipeline.fit(X_train,Y_train)  ## Execute the Final Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc2bd06",
   "metadata": {},
   "source": [
    "## **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6a6fc768",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=final_pipeline.predict(X_test) ##get the prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f2cf46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_xgb=classification_report(Y_test,Y_pred) ##get the classification report for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "feced27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train=final_pipeline.predict(X_train) ##get the preidction value for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c18df9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_xgb_train=classification_report(Y_train,Y_pred_train) ##get the classification report for training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db10f319",
   "metadata": {},
   "source": [
    "#### **Get the Evaluation Metrics for Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "110c94e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_test=f1_score(Y_test,Y_pred,average='weighted') ##F1 score for testing data\n",
    "precision_test=precision_score(Y_test,Y_pred,average=\"weighted\") ##precision for testing data\n",
    "accuracy_test=accuracy_score(Y_test,Y_pred) ## accuracy score for testing data\n",
    "recall_test=recall_score(Y_test,Y_pred,average=\"weighted\") ## recall score for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c70c79c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8100\n",
      "Precision: 0.7998\n",
      "F1 Score:  0.8034\n",
      "Recall Score: 0.8100\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(f\"Accuracy:  {accuracy_test:.4f}\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"F1 Score:  {f1_test:.4f}\")\n",
    "print(f\"Recall Score: {recall_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b27e7",
   "metadata": {},
   "source": [
    "#### **Get the Evaluation Metrics for Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1fb90f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train=f1_score(Y_train,Y_pred_train,average=\"weighted\") ##F1 score for training data\n",
    "precision_train=precision_score(Y_train,Y_pred_train,average=\"weighted\") ## precision score for training data\n",
    "accuracy_train=accuracy_score(Y_train,Y_pred_train) ## accuracy score for training data\n",
    "recall_train=recall_score(Y_train,Y_pred_train,average=\"weighted\") ##recall score for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f101df59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8657\n",
      "Precision: 0.8627\n",
      "F1 Score:  0.8623\n",
      "Recall Score:0.8657\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(f\"Accuracy:  {accuracy_train:.4f}\")\n",
    "print(f\"Precision: {precision_train:.4f}\")\n",
    "print(f\"F1 Score:  {f1_train:.4f}\")\n",
    "print(f\"Recall Score:{recall_train:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4be47791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.37      0.41        54\n",
      "           1       1.00      1.00      1.00       125\n",
      "           2       0.74      0.81      0.77       121\n",
      "\n",
      "    accuracy                           0.81       300\n",
      "   macro avg       0.74      0.73      0.73       300\n",
      "weighted avg       0.80      0.81      0.80       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### print the classification report for testing data\n",
    "print(report_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "275fe511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.59      0.65       148\n",
      "           1       1.00      1.00      1.00       276\n",
      "           2       0.80      0.88      0.84       276\n",
      "\n",
      "    accuracy                           0.87       700\n",
      "   macro avg       0.84      0.82      0.83       700\n",
      "weighted avg       0.86      0.87      0.86       700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print the classification report for training data\n",
    "print(report_xgb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb6db36",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tune using Grid SearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c65a848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'XGB Classifier__n_estimators': [100, 200],\n",
    "    'XGB Classifier__max_depth': [3, 5, 7],\n",
    "    'XGB Classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'XGB Classifier__subsample': [0.6, 0.8, 1.0],\n",
    "    'XGB Classifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'XGB Classifier__reg_alpha': [0, 0.1, 1, 10],     # L1 regularization\n",
    "    'XGB Classifier__reg_lambda': [0, 0.1, 1, 10]     # L2 regularization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5932cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV(final_pipeline,param_grid=param_grid,cv=5,scoring=\"f1_weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fdabe0",
   "metadata": {},
   "source": [
    "#### **Execute the Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4cba0e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-9 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-9 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-9 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-9 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-9 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-9 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-9 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-9 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-9 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;Preprocessing&#x27;,\n",
       "                                        ColumnTransformer(n_jobs=-1,\n",
       "                                                          transformers=[(&#x27;Ordinal &#x27;\n",
       "                                                                         &#x27;Pipeline&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;Ordinal &#x27;\n",
       "                                                                                          &#x27;Encoder&#x27;,\n",
       "                                                                                          OrdinalEncoder())]),\n",
       "                                                                         [&#x27;work_status&#x27;,\n",
       "                                                                          &#x27;social_activity_level&#x27;,\n",
       "                                                                          &#x27;exercise_frequency&#x27;]),\n",
       "                                                                        (&#x27;Nominal &#x27;\n",
       "                                                                         &#x27;Pipeline&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;Nominal &#x27;\n",
       "                                                                                          &#x27;Encoder&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                                        sparse_output...\n",
       "                                                      num_parallel_tree=None, ...))]),\n",
       "             param_grid={&#x27;XGB Classifier__colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n",
       "                         &#x27;XGB Classifier__learning_rate&#x27;: [0.01, 0.05, 0.1,\n",
       "                                                           0.2],\n",
       "                         &#x27;XGB Classifier__max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;XGB Classifier__n_estimators&#x27;: [100, 200],\n",
       "                         &#x27;XGB Classifier__reg_alpha&#x27;: [0, 0.1, 1, 10],\n",
       "                         &#x27;XGB Classifier__reg_lambda&#x27;: [0, 0.1, 1, 10],\n",
       "                         &#x27;XGB Classifier__subsample&#x27;: [0.6, 0.8, 1.0]},\n",
       "             scoring=&#x27;f1_weighted&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;Preprocessing&#x27;,\n",
       "                                        ColumnTransformer(n_jobs=-1,\n",
       "                                                          transformers=[(&#x27;Ordinal &#x27;\n",
       "                                                                         &#x27;Pipeline&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;Ordinal &#x27;\n",
       "                                                                                          &#x27;Encoder&#x27;,\n",
       "                                                                                          OrdinalEncoder())]),\n",
       "                                                                         [&#x27;work_status&#x27;,\n",
       "                                                                          &#x27;social_activity_level&#x27;,\n",
       "                                                                          &#x27;exercise_frequency&#x27;]),\n",
       "                                                                        (&#x27;Nominal &#x27;\n",
       "                                                                         &#x27;Pipeline&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;Nominal &#x27;\n",
       "                                                                                          &#x27;Encoder&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                                        sparse_output...\n",
       "                                                      num_parallel_tree=None, ...))]),\n",
       "             param_grid={&#x27;XGB Classifier__colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n",
       "                         &#x27;XGB Classifier__learning_rate&#x27;: [0.01, 0.05, 0.1,\n",
       "                                                           0.2],\n",
       "                         &#x27;XGB Classifier__max_depth&#x27;: [3, 5, 7],\n",
       "                         &#x27;XGB Classifier__n_estimators&#x27;: [100, 200],\n",
       "                         &#x27;XGB Classifier__reg_alpha&#x27;: [0, 0.1, 1, 10],\n",
       "                         &#x27;XGB Classifier__reg_lambda&#x27;: [0, 0.1, 1, 10],\n",
       "                         &#x27;XGB Classifier__subsample&#x27;: [0.6, 0.8, 1.0]},\n",
       "             scoring=&#x27;f1_weighted&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;Preprocessing&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;Ordinal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Ordinal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;work_status&#x27;,\n",
       "                                                   &#x27;social_activity_level&#x27;,\n",
       "                                                   &#x27;exercise_frequency&#x27;]),\n",
       "                                                 (&#x27;Nominal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Nominal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;pem_presen...\n",
       "                               feature_types=None, feature_weights=None,\n",
       "                               gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.2,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=5, max_leaves=None, min_child_weight=3,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=200,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Preprocessing: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for Preprocessing: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(n_jobs=-1,\n",
       "                  transformers=[(&#x27;Ordinal Pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Ordinal Encoder&#x27;,\n",
       "                                                  OrdinalEncoder())]),\n",
       "                                 [&#x27;work_status&#x27;, &#x27;social_activity_level&#x27;,\n",
       "                                  &#x27;exercise_frequency&#x27;]),\n",
       "                                (&#x27;Nominal Pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Nominal Encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;gender&#x27;, &#x27;pem_present&#x27;,\n",
       "                                  &#x27;meditation_or_mindfulness&#x27;])],\n",
       "                  verbose=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Ordinal Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;work_status&#x27;, &#x27;social_activity_level&#x27;, &#x27;exercise_frequency&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OrdinalEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">?<span>Documentation for OrdinalEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OrdinalEncoder()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Nominal Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;gender&#x27;, &#x27;pem_present&#x27;, &#x27;meditation_or_mindfulness&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SMOTE</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(random_state=42)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=3, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('Preprocessing',\n",
       "                                        ColumnTransformer(n_jobs=-1,\n",
       "                                                          transformers=[('Ordinal '\n",
       "                                                                         'Pipeline',\n",
       "                                                                         Pipeline(steps=[('Ordinal '\n",
       "                                                                                          'Encoder',\n",
       "                                                                                          OrdinalEncoder())]),\n",
       "                                                                         ['work_status',\n",
       "                                                                          'social_activity_level',\n",
       "                                                                          'exercise_frequency']),\n",
       "                                                                        ('Nominal '\n",
       "                                                                         'Pipeline',\n",
       "                                                                         Pipeline(steps=[('Nominal '\n",
       "                                                                                          'Encoder',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                        sparse_output...\n",
       "                                                      num_parallel_tree=None, ...))]),\n",
       "             param_grid={'XGB Classifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                         'XGB Classifier__learning_rate': [0.01, 0.05, 0.1,\n",
       "                                                           0.2],\n",
       "                         'XGB Classifier__max_depth': [3, 5, 7],\n",
       "                         'XGB Classifier__n_estimators': [100, 200],\n",
       "                         'XGB Classifier__reg_alpha': [0, 0.1, 1, 10],\n",
       "                         'XGB Classifier__reg_lambda': [0, 0.1, 1, 10],\n",
       "                         'XGB Classifier__subsample': [0.6, 0.8, 1.0]},\n",
       "             scoring='f1_weighted')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b57539",
   "metadata": {},
   "source": [
    "#### **Best Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e3bf348b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XGB Classifier__colsample_bytree': 0.8, 'XGB Classifier__learning_rate': 0.2, 'XGB Classifier__max_depth': 5, 'XGB Classifier__n_estimators': 200, 'XGB Classifier__reg_alpha': 0, 'XGB Classifier__reg_lambda': 0.1, 'XGB Classifier__subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "best_parameters=grid_search.best_params_\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "76bd6203",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5dfc31b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-10 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-10 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-10 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-10 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-10 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-10 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-10 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-10 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-10 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Preprocessing&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;Ordinal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Ordinal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;work_status&#x27;,\n",
       "                                                   &#x27;social_activity_level&#x27;,\n",
       "                                                   &#x27;exercise_frequency&#x27;]),\n",
       "                                                 (&#x27;Nominal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Nominal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;pem_presen...\n",
       "                               feature_types=None, feature_weights=None,\n",
       "                               gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.2,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=5, max_leaves=None, min_child_weight=3,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=200,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;Preprocessing&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;Ordinal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Ordinal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;work_status&#x27;,\n",
       "                                                   &#x27;social_activity_level&#x27;,\n",
       "                                                   &#x27;exercise_frequency&#x27;]),\n",
       "                                                 (&#x27;Nominal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Nominal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;pem_presen...\n",
       "                               feature_types=None, feature_weights=None,\n",
       "                               gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.2,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=5, max_leaves=None, min_child_weight=3,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=200,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Preprocessing: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for Preprocessing: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(n_jobs=-1,\n",
       "                  transformers=[(&#x27;Ordinal Pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Ordinal Encoder&#x27;,\n",
       "                                                  OrdinalEncoder())]),\n",
       "                                 [&#x27;work_status&#x27;, &#x27;social_activity_level&#x27;,\n",
       "                                  &#x27;exercise_frequency&#x27;]),\n",
       "                                (&#x27;Nominal Pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Nominal Encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;gender&#x27;, &#x27;pem_present&#x27;,\n",
       "                                  &#x27;meditation_or_mindfulness&#x27;])],\n",
       "                  verbose=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Ordinal Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;work_status&#x27;, &#x27;social_activity_level&#x27;, &#x27;exercise_frequency&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OrdinalEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">?<span>Documentation for OrdinalEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OrdinalEncoder()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Nominal Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;gender&#x27;, &#x27;pem_present&#x27;, &#x27;meditation_or_mindfulness&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SMOTE</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(random_state=42)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=3, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Preprocessing',\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[('Ordinal Pipeline',\n",
       "                                                  Pipeline(steps=[('Ordinal '\n",
       "                                                                   'Encoder',\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  ['work_status',\n",
       "                                                   'social_activity_level',\n",
       "                                                   'exercise_frequency']),\n",
       "                                                 ('Nominal Pipeline',\n",
       "                                                  Pipeline(steps=[('Nominal '\n",
       "                                                                   'Encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['gender', 'pem_presen...\n",
       "                               feature_types=None, feature_weights=None,\n",
       "                               gamma=None, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.2,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=5, max_leaves=None, min_child_weight=3,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=200,\n",
       "                               n_jobs=None, num_parallel_tree=None, ...))])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cca83b",
   "metadata": {},
   "source": [
    "## **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "77294da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_cv=best_model.predict(X_test) ##get the prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e41f480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_xgb_cv=classification_report(Y_test,Y_pred_cv) ##get the classification report for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a290acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train_cv=best_model.predict(X_train) ##get the preidction value for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5eff51eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_xgb_train_cv=classification_report(Y_train,Y_pred_train_cv) ##get the classification report for training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc2645",
   "metadata": {},
   "source": [
    "#### **Get the Evaluation Metrics for Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a6dff47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_test=f1_score(Y_test,Y_pred_cv,average='weighted') ##F1 score for testing data\n",
    "precision_test=precision_score(Y_test,Y_pred_cv,average=\"weighted\") ##precision for testing data\n",
    "accuracy_test=accuracy_score(Y_test,Y_pred_cv) ## accuracy score for testing data\n",
    "recall_test=recall_score(Y_test,Y_pred_cv,average=\"weighted\") ## recall score for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a5fb3e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8100\n",
      "Precision: 0.7981\n",
      "F1 Score:  0.8018\n",
      "Recall Score: 0.8100\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(f\"Accuracy:  {accuracy_test:.4f}\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"F1 Score:  {f1_test:.4f}\")\n",
    "print(f\"Recall Score: {recall_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9a6f4",
   "metadata": {},
   "source": [
    "#### **Get the Evaluation Metrics for Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "093a7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train=f1_score(Y_train,Y_pred_train_cv,average=\"weighted\") ##F1 score for training data\n",
    "precision_train=precision_score(Y_train,Y_pred_train_cv,average=\"weighted\") ## precision score for training data\n",
    "accuracy_train=accuracy_score(Y_train,Y_pred_train_cv) ## accuracy score for training data\n",
    "recall_train=recall_score(Y_train,Y_pred_train_cv,average=\"weighted\") ##recall score for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b428aebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8714\n",
      "Precision: 0.8692\n",
      "F1 Score:  0.8668\n",
      "Recall Score:0.8714\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(f\"Accuracy:  {accuracy_train:.4f}\")\n",
    "print(f\"Precision: {precision_train:.4f}\")\n",
    "print(f\"F1 Score:  {f1_train:.4f}\")\n",
    "print(f\"Recall Score:{recall_train:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa12921",
   "metadata": {},
   "source": [
    "## **Hyperparameter Tune Using Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e9a9d63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "61fee4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trials):\n",
    "    ##define parameters \n",
    "    params = {\n",
    "        \"n_estimators\": trials.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"max_depth\": trials.suggest_int(\"max_depth\", 3, 15),\n",
    "        \"learning_rate\": trials.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trials.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trials.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trials.suggest_float(\"gamma\", 0, 5),\n",
    "        \"reg_alpha\": trials.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trials.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"min_child_weight\": trials.suggest_int(\"min_child_weight\", 1, 20),\n",
    "        \"scale_pos_weight\": trials.suggest_float(\"scale_pos_weight\", 1, 10),\n",
    "        \"reg_alpha\": trials.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),     # L1 regularization\n",
    "        \"reg_lambda\": trials.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),   # L2 regularization\n",
    "        \"n_jobs\": -1,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"logloss\"  # or \"mlogloss\" for multiclass\n",
    "    }\n",
    "\n",
    "    ##Build the pipeline\n",
    "    pipeline_optuna=Pipeline(steps=[\n",
    "        (\"Preprocessing\",Transfomers),\n",
    "        (\"Resampling SMOTE\",SMOTE(random_state=42)),\n",
    "        (\"Random Forest Classifier\",XGBClassifier(**params,random_state=42))\n",
    "    ])\n",
    "\n",
    "    ##cross validation score\n",
    "    score=cross_val_score(pipeline_optuna,X_train,Y_train,cv=5,scoring=\"f1_weighted\")\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20560c",
   "metadata": {},
   "source": [
    "#### **Run the Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5c50b348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-25 22:28:34,739] A new study created in memory with name: xgb_model\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:39,594] Trial 0 finished with value: 0.7072013540670516 and parameters: {'n_estimators': 196, 'max_depth': 14, 'learning_rate': 0.13406235759072194, 'subsample': 0.8403079245137743, 'colsample_bytree': 0.8324942641278905, 'gamma': 4.80214839261941, 'reg_alpha': 8.786298974032826e-08, 'reg_lambda': 0.009211073052572594, 'min_child_weight': 12, 'scale_pos_weight': 2.6568753396341043}. Best is trial 0 with value: 0.7072013540670516.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:40,654] Trial 1 finished with value: 0.7017034411098069 and parameters: {'n_estimators': 203, 'max_depth': 15, 'learning_rate': 0.05174350024726952, 'subsample': 0.7274358092855222, 'colsample_bytree': 0.9481374482964745, 'gamma': 2.6120343778162702, 'reg_alpha': 0.2699379648758439, 'reg_lambda': 0.005306011284537532, 'min_child_weight': 10, 'scale_pos_weight': 1.7093540504046754}. Best is trial 0 with value: 0.7072013540670516.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:42,173] Trial 2 finished with value: 0.6567755420631985 and parameters: {'n_estimators': 341, 'max_depth': 14, 'learning_rate': 0.025871558834316542, 'subsample': 0.9644203558011696, 'colsample_bytree': 0.5483912285544752, 'gamma': 4.756722015274971, 'reg_alpha': 0.03017660569380126, 'reg_lambda': 0.07591765932258439, 'min_child_weight': 2, 'scale_pos_weight': 2.069995175963254}. Best is trial 0 with value: 0.7072013540670516.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:43,908] Trial 3 finished with value: 0.6957322693280432 and parameters: {'n_estimators': 412, 'max_depth': 14, 'learning_rate': 0.014734394719281946, 'subsample': 0.5239678234664127, 'colsample_bytree': 0.7105347033494712, 'gamma': 3.2572510826887173, 'reg_alpha': 9.543327607527583e-06, 'reg_lambda': 8.578805849566754, 'min_child_weight': 15, 'scale_pos_weight': 8.09956536321709}. Best is trial 0 with value: 0.7072013540670516.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:46,072] Trial 4 finished with value: 0.7173970355805959 and parameters: {'n_estimators': 487, 'max_depth': 9, 'learning_rate': 0.010305941276082779, 'subsample': 0.5702937844457577, 'colsample_bytree': 0.8948827916182243, 'gamma': 2.3446858264661934, 'reg_alpha': 0.000941467413766862, 'reg_lambda': 9.205619097309081e-07, 'min_child_weight': 16, 'scale_pos_weight': 5.650847426093809}. Best is trial 4 with value: 0.7173970355805959.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:47,911] Trial 5 finished with value: 0.7131569740806732 and parameters: {'n_estimators': 408, 'max_depth': 15, 'learning_rate': 0.016208741356054407, 'subsample': 0.6578475411014445, 'colsample_bytree': 0.5107188193526584, 'gamma': 2.750435161757343, 'reg_alpha': 1.189987484141656e-08, 'reg_lambda': 3.46135148947884e-07, 'min_child_weight': 3, 'scale_pos_weight': 1.8046901870176792}. Best is trial 4 with value: 0.7173970355805959.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:48,694] Trial 6 finished with value: 0.7032011916268168 and parameters: {'n_estimators': 157, 'max_depth': 7, 'learning_rate': 0.16279546147932183, 'subsample': 0.8629864510328694, 'colsample_bytree': 0.8284480766329766, 'gamma': 0.7793748699865805, 'reg_alpha': 0.0010590653799992793, 'reg_lambda': 2.8601015308048143e-05, 'min_child_weight': 10, 'scale_pos_weight': 3.4047828787031635}. Best is trial 4 with value: 0.7173970355805959.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:49,864] Trial 7 finished with value: 0.6984766591094277 and parameters: {'n_estimators': 241, 'max_depth': 6, 'learning_rate': 0.015364566256019186, 'subsample': 0.7320291272201724, 'colsample_bytree': 0.6666440691005402, 'gamma': 4.847515707501061, 'reg_alpha': 6.002859398115578e-05, 'reg_lambda': 2.267564483164782e-06, 'min_child_weight': 18, 'scale_pos_weight': 8.30769156734858}. Best is trial 4 with value: 0.7173970355805959.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:51,265] Trial 8 finished with value: 0.7017637274222059 and parameters: {'n_estimators': 291, 'max_depth': 6, 'learning_rate': 0.010074129970141104, 'subsample': 0.7944061024297915, 'colsample_bytree': 0.781021108652717, 'gamma': 4.77345754854614, 'reg_alpha': 1.700333102780398e-05, 'reg_lambda': 1.269540965218755e-07, 'min_child_weight': 16, 'scale_pos_weight': 4.62745458376634}. Best is trial 4 with value: 0.7173970355805959.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:52,798] Trial 9 finished with value: 0.7104985474776863 and parameters: {'n_estimators': 310, 'max_depth': 6, 'learning_rate': 0.030650410767446012, 'subsample': 0.6374084229800705, 'colsample_bytree': 0.5383830480056969, 'gamma': 1.1840025788799795, 'reg_alpha': 8.061652078985138e-05, 'reg_lambda': 7.54265377027969e-06, 'min_child_weight': 15, 'scale_pos_weight': 7.958246117061741}. Best is trial 4 with value: 0.7173970355805959.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:55,460] Trial 10 finished with value: 0.723581430371937 and parameters: {'n_estimators': 497, 'max_depth': 10, 'learning_rate': 0.08083902823500068, 'subsample': 0.5073691744537723, 'colsample_bytree': 0.9773550662761795, 'gamma': 0.013444524372371092, 'reg_alpha': 2.985695411936949, 'reg_lambda': 3.1592180655672634e-08, 'min_child_weight': 20, 'scale_pos_weight': 6.0894949832843}. Best is trial 10 with value: 0.723581430371937.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:57,189] Trial 11 finished with value: 0.6977514712737456 and parameters: {'n_estimators': 489, 'max_depth': 10, 'learning_rate': 0.09668434392770486, 'subsample': 0.5292332655366927, 'colsample_bytree': 0.9777264389754541, 'gamma': 0.23526947572567725, 'reg_alpha': 9.811816017039117, 'reg_lambda': 1.2325022745799217e-08, 'min_child_weight': 20, 'scale_pos_weight': 5.805477701678883}. Best is trial 10 with value: 0.723581430371937.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:28:58,908] Trial 12 finished with value: 0.6932504028142559 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.26250808772588047, 'subsample': 0.5951603358593608, 'colsample_bytree': 0.9049471136633052, 'gamma': 1.8052948308210484, 'reg_alpha': 8.243633326769977, 'reg_lambda': 1.6066465148555592e-08, 'min_child_weight': 20, 'scale_pos_weight': 6.284246314868023}. Best is trial 10 with value: 0.723581430371937.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:28:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:00,565] Trial 13 finished with value: 0.7198414213834002 and parameters: {'n_estimators': 432, 'max_depth': 3, 'learning_rate': 0.065794665994381, 'subsample': 0.5219564668867904, 'colsample_bytree': 0.9054304110408955, 'gamma': 3.6167721357968676, 'reg_alpha': 0.006816907770968441, 'reg_lambda': 0.00019614971654610002, 'min_child_weight': 13, 'scale_pos_weight': 6.558396701994521}. Best is trial 10 with value: 0.723581430371937.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:02,197] Trial 14 finished with value: 0.7063135906654763 and parameters: {'n_estimators': 402, 'max_depth': 4, 'learning_rate': 0.06417799901108147, 'subsample': 0.5005674875845653, 'colsample_bytree': 0.9900684122964014, 'gamma': 3.7454837736560185, 'reg_alpha': 0.061777776872981575, 'reg_lambda': 0.00019271495171356367, 'min_child_weight': 12, 'scale_pos_weight': 9.53210915151299}. Best is trial 10 with value: 0.723581430371937.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:04,004] Trial 15 finished with value: 0.6840343655707104 and parameters: {'n_estimators': 435, 'max_depth': 3, 'learning_rate': 0.061671602274980794, 'subsample': 0.6692319993445934, 'colsample_bytree': 0.8817445082155604, 'gamma': 3.9070906848385683, 'reg_alpha': 0.5658734323728953, 'reg_lambda': 0.6870153178707895, 'min_child_weight': 8, 'scale_pos_weight': 6.984046938510349}. Best is trial 10 with value: 0.723581430371937.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:05,541] Trial 16 finished with value: 0.7180010520188187 and parameters: {'n_estimators': 356, 'max_depth': 11, 'learning_rate': 0.0909494858109778, 'subsample': 0.5959524430356258, 'colsample_bytree': 0.6400314534479783, 'gamma': 1.7239679995921542, 'reg_alpha': 0.008111317797940321, 'reg_lambda': 0.00028388362996662793, 'min_child_weight': 6, 'scale_pos_weight': 3.7073384916524335}. Best is trial 10 with value: 0.723581430371937.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:06,327] Trial 17 finished with value: 0.6931571378999501 and parameters: {'n_estimators': 104, 'max_depth': 12, 'learning_rate': 0.03547600589396836, 'subsample': 0.5644691445475986, 'colsample_bytree': 0.9348827467674048, 'gamma': 3.9076617600525467, 'reg_alpha': 1.0904402911634625, 'reg_lambda': 0.002791135302800152, 'min_child_weight': 13, 'scale_pos_weight': 4.51973429201472}. Best is trial 10 with value: 0.723581430371937.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:09,821] Trial 18 finished with value: 0.7213740191801593 and parameters: {'n_estimators': 443, 'max_depth': 8, 'learning_rate': 0.04290598626987626, 'subsample': 0.6720868696973685, 'colsample_bytree': 0.8319329671669895, 'gamma': 0.17786917180062975, 'reg_alpha': 7.827998045526231e-07, 'reg_lambda': 3.489906496655594e-05, 'min_child_weight': 6, 'scale_pos_weight': 7.032992461513464}. Best is trial 10 with value: 0.723581430371937.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:13,101] Trial 19 finished with value: 0.7217326635278831 and parameters: {'n_estimators': 456, 'max_depth': 8, 'learning_rate': 0.04572231983442214, 'subsample': 0.6950258836713447, 'colsample_bytree': 0.7948039590280238, 'gamma': 0.1796170715922597, 'reg_alpha': 1.152992508580821e-06, 'reg_lambda': 1.8755852355524932e-05, 'min_child_weight': 5, 'scale_pos_weight': 9.957968231951405}. Best is trial 10 with value: 0.723581430371937.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:14,503] Trial 20 finished with value: 0.7072357510989147 and parameters: {'n_estimators': 363, 'max_depth': 12, 'learning_rate': 0.28355848343708406, 'subsample': 0.9920025425557798, 'colsample_bytree': 0.7502391317461019, 'gamma': 0.87670041493317, 'reg_alpha': 7.993411913766853e-07, 'reg_lambda': 9.318085105134316e-08, 'min_child_weight': 4, 'scale_pos_weight': 9.654148081213517}. Best is trial 10 with value: 0.723581430371937.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:18,554] Trial 21 finished with value: 0.7196272883465255 and parameters: {'n_estimators': 455, 'max_depth': 8, 'learning_rate': 0.04226566362447649, 'subsample': 0.6879487196709283, 'colsample_bytree': 0.8297620320231864, 'gamma': 0.03949057133854286, 'reg_alpha': 1.0552448572736425e-06, 'reg_lambda': 2.3562998979655504e-05, 'min_child_weight': 6, 'scale_pos_weight': 7.039043789204588}. Best is trial 10 with value: 0.723581430371937.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:21,801] Trial 22 finished with value: 0.7244032255091921 and parameters: {'n_estimators': 460, 'max_depth': 8, 'learning_rate': 0.02246433877233089, 'subsample': 0.795050002199258, 'colsample_bytree': 0.7876408558403054, 'gamma': 0.48308030783070066, 'reg_alpha': 1.2130639629888176e-06, 'reg_lambda': 5.850580993372042e-06, 'min_child_weight': 1, 'scale_pos_weight': 8.570783673015164}. Best is trial 22 with value: 0.7244032255091921.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:25,166] Trial 23 finished with value: 0.7140193557164507 and parameters: {'n_estimators': 477, 'max_depth': 9, 'learning_rate': 0.026756802398505256, 'subsample': 0.7902481455041968, 'colsample_bytree': 0.7730806154904075, 'gamma': 0.5968781512070802, 'reg_alpha': 9.064727150449284e-08, 'reg_lambda': 3.012287600648648e-06, 'min_child_weight': 2, 'scale_pos_weight': 9.033649412199683}. Best is trial 22 with value: 0.7244032255091921.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:28,313] Trial 24 finished with value: 0.7189778532833495 and parameters: {'n_estimators': 376, 'max_depth': 8, 'learning_rate': 0.020559354112991732, 'subsample': 0.8543416556457628, 'colsample_bytree': 0.7037568712924611, 'gamma': 0.5068079384666618, 'reg_alpha': 5.229821561379425e-06, 'reg_lambda': 8.59770937132381e-08, 'min_child_weight': 1, 'scale_pos_weight': 8.749878414045448}. Best is trial 22 with value: 0.7244032255091921.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:31,099] Trial 25 finished with value: 0.7109689774390893 and parameters: {'n_estimators': 469, 'max_depth': 11, 'learning_rate': 0.0862688766446491, 'subsample': 0.9206119813569216, 'colsample_bytree': 0.6417657063131771, 'gamma': 1.2939640674930937, 'reg_alpha': 1.3303339383831818e-08, 'reg_lambda': 7.069766088317646e-07, 'min_child_weight': 8, 'scale_pos_weight': 9.77596996981809}. Best is trial 22 with value: 0.7244032255091921.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:33,719] Trial 26 finished with value: 0.7167481013765545 and parameters: {'n_estimators': 387, 'max_depth': 5, 'learning_rate': 0.12582552323608298, 'subsample': 0.7676277545010577, 'colsample_bytree': 0.791709668912126, 'gamma': 1.2318734325708747, 'reg_alpha': 0.00013151462944826342, 'reg_lambda': 0.0014291223622997693, 'min_child_weight': 4, 'scale_pos_weight': 7.658093140756659}. Best is trial 22 with value: 0.7244032255091921.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:36,709] Trial 27 finished with value: 0.7245439606854193 and parameters: {'n_estimators': 323, 'max_depth': 7, 'learning_rate': 0.020856843402405015, 'subsample': 0.8953188779354669, 'colsample_bytree': 0.5954482315268514, 'gamma': 0.41983790123338277, 'reg_alpha': 1.431655906415745e-07, 'reg_lambda': 9.604638964637699e-06, 'min_child_weight': 1, 'scale_pos_weight': 9.014759553364101}. Best is trial 27 with value: 0.7245439606854193.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:39,009] Trial 28 finished with value: 0.7162457815698435 and parameters: {'n_estimators': 281, 'max_depth': 7, 'learning_rate': 0.019550491478364573, 'subsample': 0.903679376712912, 'colsample_bytree': 0.5930822495257854, 'gamma': 1.6408705435487392, 'reg_alpha': 1.044865137753858e-07, 'reg_lambda': 3.251190306013642e-06, 'min_child_weight': 1, 'scale_pos_weight': 8.788744885941787}. Best is trial 27 with value: 0.7245439606854193.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:40,766] Trial 29 finished with value: 0.7085974288134108 and parameters: {'n_estimators': 331, 'max_depth': 9, 'learning_rate': 0.17800374981992204, 'subsample': 0.818805589216214, 'colsample_bytree': 0.7125230616111544, 'gamma': 0.5226202706028484, 'reg_alpha': 1.9386299846217692e-07, 'reg_lambda': 8.441640176275075e-05, 'min_child_weight': 9, 'scale_pos_weight': 5.017952346173591}. Best is trial 27 with value: 0.7245439606854193.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:42,014] Trial 30 finished with value: 0.7022708659992001 and parameters: {'n_estimators': 256, 'max_depth': 5, 'learning_rate': 0.02143048693331766, 'subsample': 0.8946838701425779, 'colsample_bytree': 0.5661924419446556, 'gamma': 2.1521536506348835, 'reg_alpha': 4.509632888190974e-06, 'reg_lambda': 0.02053000988926343, 'min_child_weight': 18, 'scale_pos_weight': 7.522348112875417}. Best is trial 27 with value: 0.7245439606854193.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:44,070] Trial 31 finished with value: 0.7062959585619207 and parameters: {'n_estimators': 461, 'max_depth': 7, 'learning_rate': 0.03532099634112206, 'subsample': 0.9354557660108821, 'colsample_bytree': 0.8532805103920851, 'gamma': 0.3528494775907105, 'reg_alpha': 3.1226027311502014e-07, 'reg_lambda': 1.3148726093845627e-05, 'min_child_weight': 4, 'scale_pos_weight': 9.053267234815365}. Best is trial 27 with value: 0.7245439606854193.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:46,290] Trial 32 finished with value: 0.7162079665035309 and parameters: {'n_estimators': 425, 'max_depth': 10, 'learning_rate': 0.049200457167187885, 'subsample': 0.7491494154993468, 'colsample_bytree': 0.741661298200367, 'gamma': 0.9507255330008182, 'reg_alpha': 4.338060839886676e-08, 'reg_lambda': 3.587825737083745e-07, 'min_child_weight': 3, 'scale_pos_weight': 9.834402793117091}. Best is trial 27 with value: 0.7245439606854193.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:48,515] Trial 33 finished with value: 0.7333526615712413 and parameters: {'n_estimators': 218, 'max_depth': 8, 'learning_rate': 0.024393795806414396, 'subsample': 0.7101454952537408, 'colsample_bytree': 0.7988098844323009, 'gamma': 0.2627028781812354, 'reg_alpha': 1.5456837930390957e-06, 'reg_lambda': 0.0014544300859966855, 'min_child_weight': 1, 'scale_pos_weight': 8.412022531679098}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:50,072] Trial 34 finished with value: 0.7229840949580376 and parameters: {'n_estimators': 191, 'max_depth': 7, 'learning_rate': 0.014091470615568695, 'subsample': 0.8750377512075982, 'colsample_bytree': 0.6010141680787091, 'gamma': 0.6380807075521931, 'reg_alpha': 2.077361566322969e-05, 'reg_lambda': 0.0006958262089114908, 'min_child_weight': 1, 'scale_pos_weight': 8.269112309040903}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:53,308] Trial 35 finished with value: 0.723664774600835 and parameters: {'n_estimators': 216, 'max_depth': 12, 'learning_rate': 0.026368682923899527, 'subsample': 0.8195545113247222, 'colsample_bytree': 0.9455459297084738, 'gamma': 0.03227186891304584, 'reg_alpha': 2.7882147159824506e-06, 'reg_lambda': 0.014544233407569692, 'min_child_weight': 2, 'scale_pos_weight': 7.48364318597372}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:54,668] Trial 36 finished with value: 0.7141120407482917 and parameters: {'n_estimators': 194, 'max_depth': 13, 'learning_rate': 0.026573996420358032, 'subsample': 0.8282334552032953, 'colsample_bytree': 0.8637516254198639, 'gamma': 1.0106917811990204, 'reg_alpha': 3.4757704142257265e-06, 'reg_lambda': 0.013500485314666027, 'min_child_weight': 2, 'scale_pos_weight': 8.516015629008521}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:57,089] Trial 37 finished with value: 0.709145164527308 and parameters: {'n_estimators': 225, 'max_depth': 15, 'learning_rate': 0.01855923279918052, 'subsample': 0.7145980395431767, 'colsample_bytree': 0.9354098800203215, 'gamma': 0.403521542899004, 'reg_alpha': 3.516633507447328e-08, 'reg_lambda': 0.07258761971163889, 'min_child_weight': 3, 'scale_pos_weight': 1.1051037270377941}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:58,293] Trial 38 finished with value: 0.7152049572591246 and parameters: {'n_estimators': 156, 'max_depth': 9, 'learning_rate': 0.013553337340219464, 'subsample': 0.7857197326620904, 'colsample_bytree': 0.6922771923634549, 'gamma': 1.5670337277379445, 'reg_alpha': 3.0160920794998736e-07, 'reg_lambda': 0.9022675692157047, 'min_child_weight': 1, 'scale_pos_weight': 9.160681079110168}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:29:59,272] Trial 39 finished with value: 0.7164448606518945 and parameters: {'n_estimators': 162, 'max_depth': 5, 'learning_rate': 0.025009403595759882, 'subsample': 0.950115170789824, 'colsample_bytree': 0.7459900410962736, 'gamma': 3.044038338708705, 'reg_alpha': 2.109936351645412e-05, 'reg_lambda': 0.0054456786128162975, 'min_child_weight': 2, 'scale_pos_weight': 7.700780923107767}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:29:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:30:02,174] Trial 40 finished with value: 0.7063491172683591 and parameters: {'n_estimators': 220, 'max_depth': 11, 'learning_rate': 0.01150913598179345, 'subsample': 0.8169582658944251, 'colsample_bytree': 0.8150913429958728, 'gamma': 0.7621219599750242, 'reg_alpha': 0.000898382593086397, 'reg_lambda': 0.07677104574727062, 'min_child_weight': 3, 'scale_pos_weight': 8.201455938993046}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:30:05,149] Trial 41 finished with value: 0.7301916549366023 and parameters: {'n_estimators': 266, 'max_depth': 13, 'learning_rate': 0.03238002397930312, 'subsample': 0.844771933423682, 'colsample_bytree': 0.9716417726946276, 'gamma': 0.08648949784464371, 'reg_alpha': 1.6232564524355352e-06, 'reg_lambda': 0.0022076907008701315, 'min_child_weight': 2, 'scale_pos_weight': 5.893667659826667}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:30:11,624] Trial 42 finished with value: 0.7314159793458671 and parameters: {'n_estimators': 319, 'max_depth': 13, 'learning_rate': 0.03278713840675986, 'subsample': 0.8436246402464447, 'colsample_bytree': 0.9490849900675844, 'gamma': 0.007664975403590346, 'reg_alpha': 4.11425875015195e-06, 'reg_lambda': 0.029432383421832957, 'min_child_weight': 1, 'scale_pos_weight': 7.3621744236523545}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:30:14,984] Trial 43 finished with value: 0.7266384984343164 and parameters: {'n_estimators': 273, 'max_depth': 14, 'learning_rate': 0.022303469429976734, 'subsample': 0.8685874301875801, 'colsample_bytree': 0.9628974577622618, 'gamma': 0.30190073071106416, 'reg_alpha': 1.6701806254045307e-06, 'reg_lambda': 0.0011224231204581651, 'min_child_weight': 1, 'scale_pos_weight': 6.592981430877327}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:30:18,119] Trial 44 finished with value: 0.7105030005265727 and parameters: {'n_estimators': 270, 'max_depth': 14, 'learning_rate': 0.03205468940196566, 'subsample': 0.875806226204999, 'colsample_bytree': 0.9618126210303058, 'gamma': 0.28614164845780676, 'reg_alpha': 1.1110614358335274e-05, 'reg_lambda': 0.0016278024314631413, 'min_child_weight': 5, 'scale_pos_weight': 5.264106209864597}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:30:20,244] Trial 45 finished with value: 0.7048598231037901 and parameters: {'n_estimators': 310, 'max_depth': 13, 'learning_rate': 0.016920675963204537, 'subsample': 0.85220163091392, 'colsample_bytree': 0.9214307671374403, 'gamma': 0.7869905121238889, 'reg_alpha': 4.788395055661013e-05, 'reg_lambda': 0.000510739734939189, 'min_child_weight': 3, 'scale_pos_weight': 6.44282400274956}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:30:21,662] Trial 46 finished with value: 0.7021743421566022 and parameters: {'n_estimators': 327, 'max_depth': 13, 'learning_rate': 0.03502128047092562, 'subsample': 0.972394752011843, 'colsample_bytree': 0.9633955035051005, 'gamma': 1.1215980338428344, 'reg_alpha': 0.00021225918894061837, 'reg_lambda': 0.039879260077629965, 'min_child_weight': 5, 'scale_pos_weight': 5.911040213600627}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:30:22,870] Trial 47 finished with value: 0.7043439956377233 and parameters: {'n_estimators': 302, 'max_depth': 13, 'learning_rate': 0.030694880372754342, 'subsample': 0.8922079247881475, 'colsample_bytree': 0.9952289212741582, 'gamma': 4.370546488572253, 'reg_alpha': 3.7110532690978494e-07, 'reg_lambda': 7.9293187271271e-05, 'min_child_weight': 1, 'scale_pos_weight': 6.74816884064863}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:30:24,393] Trial 48 finished with value: 0.7252419805252527 and parameters: {'n_estimators': 252, 'max_depth': 14, 'learning_rate': 0.03893126640012987, 'subsample': 0.9203963638901215, 'colsample_bytree': 0.5058067829922535, 'gamma': 1.3423598634967222, 'reg_alpha': 2.2020645145313585e-06, 'reg_lambda': 0.4752318568858215, 'min_child_weight': 2, 'scale_pos_weight': 5.572229877198713}. Best is trial 33 with value: 0.7333526615712413.\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:30:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-07-25 22:30:25,532] Trial 49 finished with value: 0.700410139498137 and parameters: {'n_estimators': 248, 'max_depth': 15, 'learning_rate': 0.05704639798123633, 'subsample': 0.7518970469964995, 'colsample_bytree': 0.8780908681167294, 'gamma': 2.5444385595405334, 'reg_alpha': 2.3805243561832875e-06, 'reg_lambda': 1.4019218245131533, 'min_child_weight': 4, 'scale_pos_weight': 5.543999842227325}. Best is trial 33 with value: 0.7333526615712413.\n"
     ]
    }
   ],
   "source": [
    "study=optuna.create_study(\n",
    "    study_name=\"xgb_model\"\n",
    "    ,direction=\"maximize\")\n",
    "study.optimize(objective,n_trials=50) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8db1fc",
   "metadata": {},
   "source": [
    "#### **Best Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a05ebac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:{'n_estimators': 218, 'max_depth': 8, 'learning_rate': 0.024393795806414396, 'subsample': 0.7101454952537408, 'colsample_bytree': 0.7988098844323009, 'gamma': 0.2627028781812354, 'reg_alpha': 1.5456837930390957e-06, 'reg_lambda': 0.0014544300859966855, 'min_child_weight': 1, 'scale_pos_weight': 8.412022531679098}\n"
     ]
    }
   ],
   "source": [
    "best_model_optuna=study.best_params\n",
    "print(f\"Best Params:{best_model_optuna}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e9c41f",
   "metadata": {},
   "source": [
    "#### **Run the Pipeline with Best Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "84f73bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline=Pipeline(steps=[\n",
    "        (\"Preprocessing\",Transfomers),\n",
    "        (\"Resampling SMOTE\",SMOTE(random_state=42)),\n",
    "        (\"Random Forest Classifier\",XGBClassifier(random_state=42,**best_model_optuna))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2032c",
   "metadata": {},
   "source": [
    "#### **Train the Model with Best Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d4dba64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:33:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-11 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-11 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-11 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-11 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-11 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Preprocessing&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;Ordinal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Ordinal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;work_status&#x27;,\n",
       "                                                   &#x27;social_activity_level&#x27;,\n",
       "                                                   &#x27;exercise_frequency&#x27;]),\n",
       "                                                 (&#x27;Nominal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Nominal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;pem_presen...\n",
       "                               gamma=0.2627028781812354, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.024393795806414396, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=8,\n",
       "                               max_leaves=None, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=218, n_jobs=None,\n",
       "                               num_parallel_tree=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;Preprocessing&#x27;,\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[(&#x27;Ordinal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Ordinal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  [&#x27;work_status&#x27;,\n",
       "                                                   &#x27;social_activity_level&#x27;,\n",
       "                                                   &#x27;exercise_frequency&#x27;]),\n",
       "                                                 (&#x27;Nominal Pipeline&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;Nominal &#x27;\n",
       "                                                                   &#x27;Encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;gender&#x27;, &#x27;pem_presen...\n",
       "                               gamma=0.2627028781812354, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.024393795806414396, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=8,\n",
       "                               max_leaves=None, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=218, n_jobs=None,\n",
       "                               num_parallel_tree=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Preprocessing: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for Preprocessing: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(n_jobs=-1,\n",
       "                  transformers=[(&#x27;Ordinal Pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Ordinal Encoder&#x27;,\n",
       "                                                  OrdinalEncoder())]),\n",
       "                                 [&#x27;work_status&#x27;, &#x27;social_activity_level&#x27;,\n",
       "                                  &#x27;exercise_frequency&#x27;]),\n",
       "                                (&#x27;Nominal Pipeline&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;Nominal Encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;gender&#x27;, &#x27;pem_present&#x27;,\n",
       "                                  &#x27;meditation_or_mindfulness&#x27;])],\n",
       "                  verbose=True)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Ordinal Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;work_status&#x27;, &#x27;social_activity_level&#x27;, &#x27;exercise_frequency&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-86\" type=\"checkbox\" ><label for=\"sk-estimator-id-86\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OrdinalEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">?<span>Documentation for OrdinalEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OrdinalEncoder()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-87\" type=\"checkbox\" ><label for=\"sk-estimator-id-87\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Nominal Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;gender&#x27;, &#x27;pem_present&#x27;, &#x27;meditation_or_mindfulness&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" ><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SMOTE</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(random_state=42)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7988098844323009, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=0.2627028781812354, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.024393795806414396,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=218, n_jobs=None,\n",
       "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Preprocessing',\n",
       "                 ColumnTransformer(n_jobs=-1,\n",
       "                                   transformers=[('Ordinal Pipeline',\n",
       "                                                  Pipeline(steps=[('Ordinal '\n",
       "                                                                   'Encoder',\n",
       "                                                                   OrdinalEncoder())]),\n",
       "                                                  ['work_status',\n",
       "                                                   'social_activity_level',\n",
       "                                                   'exercise_frequency']),\n",
       "                                                 ('Nominal Pipeline',\n",
       "                                                  Pipeline(steps=[('Nominal '\n",
       "                                                                   'Encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['gender', 'pem_presen...\n",
       "                               gamma=0.2627028781812354, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.024393795806414396, max_bin=None,\n",
       "                               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                               max_delta_step=None, max_depth=8,\n",
       "                               max_leaves=None, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=218, n_jobs=None,\n",
       "                               num_parallel_tree=None, ...))])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pipeline.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f2df4d",
   "metadata": {},
   "source": [
    "#### **Evaluate the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "98294cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_optuna=best_pipeline.predict(X_test) ##get the prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e13a3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_xgb_optuna=classification_report(Y_test,Y_pred_optuna) ##get the classification report for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cb3a4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train_optuna=best_pipeline.predict(X_train) ##get the preidction value for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "48fbbf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_xgb_train_optuna=classification_report(Y_train,Y_pred_train_optuna) ##get the classification report for training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa64d5c",
   "metadata": {},
   "source": [
    "#### **Get the Evaluation Metrics for Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "922072f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_test=f1_score(Y_test,Y_pred_optuna,average='weighted') ##F1 score for testing data\n",
    "precision_test=precision_score(Y_test,Y_pred_optuna,average=\"weighted\") ##precision for testing data\n",
    "accuracy_test=accuracy_score(Y_test,Y_pred_optuna) ## accuracy score for testing data\n",
    "recall_test=recall_score(Y_test,Y_pred_optuna,average=\"weighted\") ## recall score for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b80839e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7967\n",
      "Precision: 0.7790\n",
      "F1 Score:  0.7843\n",
      "Recall Score:0.7967\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(f\"Accuracy:  {accuracy_test:.4f}\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"F1 Score:  {f1_test:.4f}\")\n",
    "print(f\"Recall Score:{recall_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf3177c",
   "metadata": {},
   "source": [
    "#### **Get the Evaluation Metrics for Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "055b223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train=f1_score(Y_train,Y_pred_train_optuna,average=\"weighted\") ##F1 score for training data\n",
    "precision_train=precision_score(Y_train,Y_pred_train_optuna,average=\"weighted\") ## precision score for training data\n",
    "accuracy_train=accuracy_score(Y_train,Y_pred_train_optuna) ## accuracy score for training data\n",
    "recall_train=recall_score(Y_train,Y_pred_train_optuna,average=\"weighted\") ##recall score for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f450599d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8657\n",
      "Precision: 0.8642\n",
      "F1 Score:  0.8589\n",
      "Recall Score:0.8657\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(f\"Accuracy:  {accuracy_train:.4f}\")\n",
    "print(f\"Precision: {precision_train:.4f}\")\n",
    "print(f\"F1 Score:  {f1_train:.4f}\")\n",
    "print(f\"Recall Score:{recall_train:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe0edc",
   "metadata": {},
   "source": [
    "## **Model Deployment using Mlflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4ef0be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "adcbc9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 22:34:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/25 22:34:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGB Classifier with Grid SearchCV at: http://127.0.0.1:5000/#/experiments/832579494267334109/runs/9d16d70c1a4f453bbd565e9ba3087c35\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/832579494267334109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/25 22:34:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/25 22:34:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run XGB Classifier with Optuna at: http://127.0.0.1:5000/#/experiments/832579494267334109/runs/52662ae7ece347269da40c5e561802c4\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/832579494267334109\n"
     ]
    }
   ],
   "source": [
    "import mlflow.sklearn\n",
    "import mlflow.sklearn\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "mlflow.set_experiment(\"XGB--Classifier\")\n",
    "#####Random Forest with Grid Search CV\n",
    "with mlflow.start_run(run_name=\"XGB Classifier with Grid SearchCV\"):\n",
    "    mlflow.log_params(best_parameters)\n",
    "    metrics_1={\n",
    "        \"accuracy\":accuracy_score(Y_test,Y_pred_cv),\n",
    "        \"f1-score\":f1_score(Y_test,Y_pred_cv,average='weighted'),\n",
    "        \"precision\":precision_score(Y_test,Y_pred_cv,average=\"weighted\"),\n",
    "        \"recall\":recall_score(Y_test,Y_pred_cv,average=\"weighted\")\n",
    "    }\n",
    "\n",
    "    for key,value in metrics_1.items():\n",
    "        mlflow.log_metric(key,value)\n",
    "    mlflow.sklearn.log_model(best_model,\"XGB Classifier with Grid SearchCV\")\n",
    "\n",
    "##########################################################################################\n",
    "### Random Forest with Optuna\n",
    "\n",
    "with mlflow.start_run(run_name=\"XGB Classifier with Optuna\"):\n",
    "    mlflow.log_params(best_model_optuna)\n",
    "    metrics_2={\n",
    "        \"accuracy\":accuracy_score(Y_test,Y_pred_optuna),\n",
    "        \"f1-score\":f1_score(Y_test,Y_pred_optuna,average='weighted'),\n",
    "        \"precision\":precision_score(Y_test,Y_pred_optuna,average=\"weighted\"),\n",
    "        \"recall\":recall_score(Y_test,Y_pred_optuna,average=\"weighted\")\n",
    "    }\n",
    "    for key,value in metrics_2.items():\n",
    "        mlflow.log_metric(key,value)\n",
    "    mlflow.sklearn.log_model(best_pipeline,\"XGB Classifier with Optuna\")\n",
    "######################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387bf4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
